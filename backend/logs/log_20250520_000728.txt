[2025-05-20 00:07:28] < (Code Agent) system> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:36) Agent Code Agent initialized with model openai/gpt-4.1
[2025-05-20 00:07:28] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:41) Loaded tool interfaces: [{'type': 'function', 'function': {'name': 'write_file_tool', 'description': "Creates or overwrites a file. Automatically creates intermediate directories if they don't exist.", 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'Path within the project where the file is located'}, 'file_name': {'type': 'string', 'description': 'Name of the file to create or overwrite'}, 'contents': {'type': 'string', 'description': 'Contents to write to the file'}}, 'required': ['file_path', 'file_name', 'contents']}}}, {'type': 'function', 'function': {'name': 'read_file_tool', 'description': 'Reads contents from a file in the project directory', 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'Path within the project where the file is located'}, 'file_name': {'type': 'string', 'description': 'Name of the file to read'}}, 'required': ['file_path', 'file_name']}}}, {'type': 'function', 'function': {'name': 'delete_file_tool', 'description': 'Deletes a file from the project directory', 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'Path within the project where the file is located'}, 'file_name': {'type': 'string', 'description': 'Name of the file to delete'}}, 'required': ['file_path', 'file_name']}}}, {'type': 'function', 'function': {'name': 'list_project_directory_tool', 'description': 'Lists the project directory structure in a tree format', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}}, {'type': 'function', 'function': {'name': 'edit_file_tool', 'description': 'Use this tool to make edits to an existing file, Best for edits where you need to add/remove/modify chunks of code, rather than making major changes to the file.', 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'Path within the project where the file is located'}, 'file_name': {'type': 'string', 'description': 'Name of the file to edit'}, 'code_snippet': {'type': 'string', 'description': 'Instructions or code snippet for the edit'}, 'instructions': {'type': 'string', 'description': 'Plain-English directions for how the snippet must be integrated (optional, best when its not obvious how the snippet should be integrated, like when removing code)'}}, 'required': ['file_path', 'file_name', 'code_snippet']}}}]
[2025-05-20 00:07:28] < (Code Agent) system> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:42) Available functions: ['write_file_tool', 'read_file_tool', 'delete_file_tool', 'list_project_directory_tool', 'edit_file_tool']
[2025-05-20 00:07:48] < (Code Agent) llm> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:106) LITELLM(openai/gpt-4.1)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:107) LITELLM(openai/gpt-4.1) Request Params: {'model': 'openai/gpt-4.1', 'messages': [{'role': 'system', 'content': 'You are a coding agent'}, {'role': 'user', 'content': 'can you tell me a super short story (two paragraphs) about a coder'}], 'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'write_file_tool', 'description': "Creates or overwrites a file. Automatically creates intermediate directories if they don't exist.", 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'Path within the project where the file is located'}, 'file_name': {'type': 'string', 'description': 'Name of the file to create or overwrite'}, 'contents': {'type': 'string', 'description': 'Contents to write to the file'}}, 'required': ['file_path', 'file_name', 'contents']}}}, {'type': 'function', 'function': {'name': 'read_file_tool', 'description': 'Reads contents from a file in the project directory', 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'Path within the project where the file is located'}, 'file_name': {'type': 'string', 'description': 'Name of the file to read'}}, 'required': ['file_path', 'file_name']}}}, {'type': 'function', 'function': {'name': 'delete_file_tool', 'description': 'Deletes a file from the project directory', 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'Path within the project where the file is located'}, 'file_name': {'type': 'string', 'description': 'Name of the file to delete'}}, 'required': ['file_path', 'file_name']}}}, {'type': 'function', 'function': {'name': 'list_project_directory_tool', 'description': 'Lists the project directory structure in a tree format', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}}, {'type': 'function', 'function': {'name': 'edit_file_tool', 'description': 'Use this tool to make edits to an existing file, Best for edits where you need to add/remove/modify chunks of code, rather than making major changes to the file.', 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'Path within the project where the file is located'}, 'file_name': {'type': 'string', 'description': 'Name of the file to edit'}, 'code_snippet': {'type': 'string', 'description': 'Instructions or code snippet for the edit'}, 'instructions': {'type': 'string', 'description': 'Plain-English directions for how the snippet must be integrated (optional, best when its not obvious how the snippet should be integrated, like when removing code)'}}, 'required': ['file_path', 'file_name', 'code_snippet']}}}], 'tool_choice': 'auto'}
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='A', role='assistant', function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' young', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' coder', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' named', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' Maya', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' stared', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' at', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' her', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' flick', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ering', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' screen', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' heart', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' beating', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' fast', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' She', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' had', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' worked', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:48] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724868, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' all', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' night', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' weaving', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' lines', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' of', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' code', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' into', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' a', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' delicate', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' tapestry', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' praying', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' her', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' new', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' game', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' wouldn', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='’t', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' crash', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' at', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' launch', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' At', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' sunrise', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' with', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' trembling', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' fingers', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' she', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' pressed', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' Enter', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' holding', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' her', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' breath', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' as', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' colorful', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' pixels', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' raced', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' to', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' life', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' and', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' cheerful', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' music', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' filled', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' silent', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' room', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.\n\n', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='M', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='aya', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' gr', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='inned', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' pride', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' washing', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' over', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' her', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' fatigue', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' Messages', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' from', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' friends', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' began', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' popping', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' up', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:49] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724869, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=':', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' “', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='It', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' works', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='!”', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' and', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' “', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='Wow', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' this', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' is', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' awesome', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='!”', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' She', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' leaned', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' back', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' bask', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ing', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' in', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' the', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' glow', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' of', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' accomplishment', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=',', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' already', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' dreaming', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' of', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' her', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' next', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' creation', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason='stop', index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True})
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True})
[2025-05-20 00:07:50] < (Code Agent) debug> (/Users/coltonkirsten/Desktop/SeniorThesis/SimpleAgent-coder/backend/SimpleAgent/SimpleAgent/litellm_interface.py:120) Chunk: ModelResponseStream(id='chatcmpl-3f3fca8c-43cd-43df-bd73-7f9e797a32be', created=1747724870, model='gpt-4.1', object='chat.completion.chunk', system_fingerprint='fp_2d9626f3cf', choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, content=None, role=None, function_call=None, tool_calls=None, audio=None), logprobs=None)], provider_specific_fields=None, stream_options={'include_usage': True}, usage=Usage(completion_tokens=118, prompt_tokens=350, total_tokens=468, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)))
